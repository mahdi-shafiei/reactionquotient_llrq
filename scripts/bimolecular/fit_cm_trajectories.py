#!/usr/bin/env python3
"""
Apply log-linear fitting to CM (Competitive Michaelis-Menten) trajectories.

This script loads the trajectory data generated by cm_rate_law_integrated.py
and applies the log-linear exponential mixture fitting from lnQ_loglinear_fit.py
to see how well we can approximate the complex CM dynamics.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import json
from pathlib import Path
import sys
import os

# Import the log-linear fitting function
sys.path.append(os.path.dirname(__file__))
# from lnQ_loglinear_fit import fit_lnQ_loglinear, LogLinearFit
from lnQ_loglinear_fit_cvxpy import fit_lnQ_loglinear_cvx, print_active_timescales
from K_matrix_from_modes import build_symmetric_K_and_x0, x1_of_t

# Output directory
OUT_DIR = Path("./output")
OUT_DIR.mkdir(parents=True, exist_ok=True)


def compute_reaction_quotient(A, B, C):
    """Compute Q = C^2 / (A * B) for reaction A + B <-> 2C"""
    eps = 1e-12
    return (C + eps) ** 2 / ((A + eps) * (B + eps))


def load_cm_trajectory_data():
    """Load the latest CM trajectory data from CSV files."""
    # Find the most recent trajectory files
    csv_files = list(OUT_DIR.glob("cm_timeseries_*.csv"))
    if not csv_files:
        raise FileNotFoundError("No CM trajectory files found. Run cm_rate_law_integrated.py first.")

    # Get the most recent files (assuming timestamp in filename)
    forward_files = [f for f in csv_files if "forward" in f.name]
    reverse_files = [f for f in csv_files if "reverse" in f.name]

    if not forward_files or not reverse_files:
        raise FileNotFoundError("Could not find both forward and reverse trajectory files.")

    forward_file = max(forward_files, key=lambda x: x.stat().st_mtime)
    reverse_file = max(reverse_files, key=lambda x: x.stat().st_mtime)

    print(f"Loading forward trajectory from: {forward_file.name}")
    print(f"Loading reverse trajectory from: {reverse_file.name}")

    forward_df = pd.read_csv(forward_file)
    reverse_df = pd.read_csv(reverse_file)

    # Load parameters
    param_files = list(OUT_DIR.glob("cm_params_*.json"))
    if param_files:
        param_file = max(param_files, key=lambda x: x.stat().st_mtime)
        with open(param_file) as f:
            params = json.load(f)
    else:
        params = None

    return forward_df, reverse_df, params


def compute_true_keq(params):
    """Compute true equilibrium constant from CM parameters."""
    if params is None:
        return None

    # From CM theory: Keq = (k_plus/k_minus) * (kM_C^2) / (kM_A * kM_B)
    return (params["k_plus"] / params["k_minus"]) * (params["kM_C"] ** 2) / (params["kM_A"] * params["kM_B"])


def fit_trajectory_with_different_params(t, ln_Q, true_keq=None):
    """Fit the ln(Q) trajectory with different parameter settings."""
    results = {}

    # Different parameter combinations to test
    param_sets = [
        # {"name": "default", "m": 60, "alpha": 1e-3, "beta": 1e-6, "gamma_l1": 0.0, "solver": "MOSEK"},
        # {"name": "sparse_light", "m": 60, "alpha": 1e-3, "beta": 1e-6, "gamma_l1": 1e-4, "solver": "MOSEK"},
        # {"name": "sparse_medium", "m": 60, "alpha": 1e-3, "beta": 1e-6, "gamma_l1": 1e-3, "solver": "MOSEK"},
        # {"name": "sparse_heavy", "m": 60, "alpha": 1e-3, "beta": 1e-6, "gamma_l1": 1e-2, "solver": "MOSEK"},
        # {"name": "more_modes", "m": 100, "alpha": 1e-3, "beta": 1e-6, "gamma_l1": 1e-4, "solver": "MOSEK"},
        # {"name": "less_smooth", "m": 60, "alpha": 1e-4, "beta": 1e-6, "gamma_l1": 1e-4, "solver": "MOSEK"},
        # {"name": "more_smooth", "m": 60, "alpha": 1e-2, "beta": 1e-6, "gamma_l1": 1e-4, "solver": "MOSEK"},
        # {"name": "minimal_sparse", "m": 60, "alpha": 1e-2, "beta": 1e-5, "gamma_l1": 10, "solver": "MOSEK"},
        {
            "name": "cardinality_constrained",
            "m": 60,
            "alpha": 1e-2,
            "beta": 1e-5,
            "gamma_l1": 1e-4,
            "cardinality": 2,  # limit to 2 active modes
            "solver": "MOSEK",
        },
    ]

    for params in param_sets:
        print(f"\nFitting with {params['name']} parameters:")
        print(f"  m={params['m']}, alpha={params['alpha']:.1e}, beta={params['beta']:.1e}, gamma_l1={params['gamma_l1']:.1e}")
        fit = fit_lnQ_loglinear_cvx(
            t,
            ln_Q,
            m=params["m"],
            alpha=params["alpha"],
            beta=params["beta"],
            gamma_l1=params["gamma_l1"],
            cardinality=params.get("cardinality", None),
            solver="MOSEK",
        )
        if fit is None:
            raise RuntimeError("All solvers failed")

        print_active_timescales(fit)

        # Analyze K matrix from the fit
        K_analysis = analyze_K_matrix_from_fit(fit, f"{params['name']}")

        results[params["name"]] = {"fit": fit, "params": params, "success": True, "K_analysis": K_analysis}

        print(f"  R² = {fit.r2:.4f}")
        print(
            f"  Active modes: {fit.active_idx.size}/{fit.lambdas.size} (sparsity: {(1-fit.active_idx.size/fit.lambdas.size)*100:.1f}%)"
        )
        print(f"  ln(K_eq) = {fit.b:.4f} -> K_eq = {fit.K_eq():.4e}")
        if true_keq:
            print(f"  True K_eq = {true_keq:.4e}, Error = {abs(fit.K_eq() - true_keq)/true_keq*100:.1f}%")

        # Show effect of L1 regularization
        if params["gamma_l1"] > 0:
            nonzero_weights = np.sum(fit.w > 1e-8)
            print(f"  L1 effect: {fit.w.size - nonzero_weights} weights driven to ~0")

    return results


def plot_fitting_results(t, ln_Q, results, true_keq=None, experiment_name=""):
    """Create comprehensive plots of fitting results."""

    # Filter successful results
    successful_results = {k: v for k, v in results.items() if v["success"]}

    if not successful_results:
        print("No successful fits to plot!")
        return

    n_fits = len(successful_results)
    fig = plt.figure(figsize=(15, 12))

    # Plot 1: All fits vs data
    ax1 = plt.subplot(2, 3, 1)
    ax1.plot(t, ln_Q, "ko", markersize=3, alpha=0.6, label="CM Data")
    if true_keq:
        ax1.axhline(np.log(true_keq), color="red", linestyle=":", alpha=0.7, label=f"ln(K_eq_true)")

    colors = plt.cm.tab10(np.linspace(0, 1, n_fits))
    for i, (name, result) in enumerate(successful_results.items()):
        fit = result["fit"]
        ax1.plot(t, fit.y_hat, "-", color=colors[i], linewidth=2, label=f"{name} (R²={fit.r2:.3f})")
        ax1.axhline(fit.b, color=colors[i], linestyle="--", alpha=0.5)

    ax1.set_xlabel("Time")
    ax1.set_ylabel("ln(Q)")
    ax1.set_title(f"Log-linear Fits Comparison - {experiment_name}")
    ax1.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
    ax1.grid(True, alpha=0.3)

    # Plot 2: R² comparison
    ax2 = plt.subplot(2, 3, 2)
    names = list(successful_results.keys())
    r2_values = [successful_results[name]["fit"].r2 for name in names]
    bars = ax2.bar(range(len(names)), r2_values, color=colors[: len(names)])
    ax2.set_xticks(range(len(names)))
    ax2.set_xticklabels(names, rotation=45, ha="right")
    ax2.set_ylabel("R²")
    ax2.set_title("Goodness of Fit Comparison")
    ax2.grid(True, alpha=0.3)

    # Add R² values on bars
    for bar, r2 in zip(bars, r2_values):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width() / 2.0, height + 0.001, f"{r2:.3f}", ha="center", va="bottom", fontsize=8)

    # Plot 3: Active mode counts
    ax3 = plt.subplot(2, 3, 3)
    active_counts = [successful_results[name]["fit"].active_idx.size for name in names]
    total_counts = [successful_results[name]["fit"].lambdas.size for name in names]
    bars1 = ax3.bar(range(len(names)), total_counts, color="lightgray", alpha=0.7, label="Total modes")
    bars2 = ax3.bar(range(len(names)), active_counts, color=colors[: len(names)], label="Active modes")
    ax3.set_xticks(range(len(names)))
    ax3.set_xticklabels(names, rotation=45, ha="right")
    ax3.set_ylabel("Number of modes")
    ax3.set_title("Active vs Total Modes")
    ax3.legend()
    ax3.grid(True, alpha=0.3)

    # Plot 4: Best fit residuals
    best_name = max(successful_results.keys(), key=lambda k: successful_results[k]["fit"].r2)
    best_fit = successful_results[best_name]["fit"]
    ax4 = plt.subplot(2, 3, 4)
    residuals = ln_Q - best_fit.y_hat
    ax4.plot(t, residuals, "ro", markersize=3, alpha=0.6)
    ax4.axhline(0, color="black", linestyle="-", alpha=0.3)
    ax4.set_xlabel("Time")
    ax4.set_ylabel("Residuals")
    ax4.set_title(f"Residuals - Best Fit ({best_name})")
    ax4.grid(True, alpha=0.3)

    # Plot 5: Active rates distribution for best fit
    ax5 = plt.subplot(2, 3, 5)
    active_lambdas = best_fit.K.diagonal()
    active_weights = best_fit.z0 / best_fit.s  # Get the actual weights

    # Create histogram of rates weighted by their importance
    bins = np.logspace(np.log10(active_lambdas.min()), np.log10(active_lambdas.max()), 15)
    ax5.hist(active_lambdas, bins=bins, weights=np.abs(active_weights), alpha=0.7, color="blue")
    ax5.set_xscale("log")
    ax5.set_xlabel("Relaxation Rate λ")
    ax5.set_ylabel("Weight")
    ax5.set_title(f"Active Rate Distribution ({best_name})")
    ax5.grid(True, alpha=0.3)

    # Plot 6: K_eq comparison
    ax6 = plt.subplot(2, 3, 6)
    keq_fitted = [successful_results[name]["fit"].K_eq() for name in names]
    bars = ax6.bar(range(len(names)), keq_fitted, color=colors[: len(names)])
    if true_keq:
        ax6.axhline(true_keq, color="red", linestyle=":", linewidth=2, label=f"True K_eq = {true_keq:.2e}")
        ax6.legend()
    ax6.set_xticks(range(len(names)))
    ax6.set_xticklabels(names, rotation=45, ha="right")
    ax6.set_ylabel("K_eq")
    ax6.set_title("Equilibrium Constant Estimates")
    ax6.set_yscale("log")
    ax6.grid(True, alpha=0.3)

    plt.tight_layout()

    # Save the plot
    filename = f"loglinear_fit_comparison_{experiment_name.lower()}.png"
    filepath = OUT_DIR / filename
    plt.savefig(filepath, dpi=150, bbox_inches="tight")
    print(f"\nSaved comparison plot to: {filepath}")

    # Try to show plot, but handle display issues gracefully
    try:
        plt.show()
    except Exception as e:
        print(f"Display warning: {e}")
        print("Plot saved successfully but display failed - check saved file")

    return best_name, best_fit


def analyze_trajectory_features(t, ln_Q, experiment_name=""):
    """Analyze the features of the ln(Q) trajectory."""
    print(f"\n=== Trajectory Analysis - {experiment_name} ===")

    # Basic statistics
    ln_Q_range = ln_Q.max() - ln_Q.min()
    ln_Q_final = ln_Q[-1]
    ln_Q_initial = ln_Q[0]

    print(f"Initial ln(Q): {ln_Q_initial:.4f}")
    print(f"Final ln(Q): {ln_Q_final:.4f}")
    print(f"Total change: {ln_Q_final - ln_Q_initial:.4f}")
    print(f"Range: {ln_Q_range:.4f}")

    # Estimate characteristic time scales
    # Find where trajectory reaches 90% and 50% of final value
    if abs(ln_Q_final - ln_Q_initial) > 1e-6:
        target_90 = ln_Q_initial + 0.9 * (ln_Q_final - ln_Q_initial)
        target_50 = ln_Q_initial + 0.5 * (ln_Q_final - ln_Q_initial)

        idx_90 = np.argmin(np.abs(ln_Q - target_90))
        idx_50 = np.argmin(np.abs(ln_Q - target_50))

        t_90 = t[idx_90]
        t_50 = t[idx_50]

        print(f"Time to 50% completion: {t_50:.4f}")
        print(f"Time to 90% completion: {t_90:.4f}")
        print(f"Estimated rate (1/t_90): {1.0/t_90:.4f}")

    # Look for multiple time scales (curvature analysis)
    if len(t) > 10:
        # Compute second derivative (curvature) of ln(Q)
        d2_ln_Q = np.gradient(np.gradient(ln_Q, t), t)
        curvature_changes = np.where(np.diff(np.sign(d2_ln_Q)))[0]

        print(f"Number of curvature sign changes: {len(curvature_changes)}")
        if len(curvature_changes) > 0:
            print("  -> Suggests multiple relaxation time scales")
        else:
            print("  -> Suggests single dominant time scale")


def analyze_K_matrix_from_fit(fit, experiment_name=""):
    """Analyze the implied K matrix and hidden state from the fitted exponential mixture."""
    print(f"\n=== K Matrix Analysis - {experiment_name} ===")

    # Extract active modes from the fit
    active_lambdas = fit.K.diagonal()  # Active eigenvalues
    active_weights = fit.z0 / fit.s  # Corresponding weights

    print(f"Active modes: {len(active_lambdas)}")
    print(f"Rate range: [{active_lambdas.min():.4f}, {active_lambdas.max():.4f}]")
    print(f"Rate spread: {active_lambdas.max()/active_lambdas.min():.2e}")

    # Construct symmetric K matrix and initial state
    try:
        K, x0, U = build_symmetric_K_and_x0(active_lambdas, active_weights)

        # Analyze K matrix properties
        K_eigenvals, _ = np.linalg.eigh(K)
        K_cond = np.linalg.cond(K)
        K_frobenius = np.linalg.norm(K, "fro")

        print(f"\nK Matrix Properties:")
        print(f"  Shape: {K.shape}")
        print(f"  Condition number: {K_cond:.2e}")
        print(f"  Frobenius norm: {K_frobenius:.4f}")
        print(f"  Eigenvalue range: [{K_eigenvals.min():.4f}, {K_eigenvals.max():.4f}]")

        # Verify reconstruction accuracy
        t_test = np.linspace(0, 2.0, 1000)  # Test time points
        x1_original = (active_weights * np.exp(-np.outer(t_test, active_lambdas))).sum(axis=1)
        x1_reconstructed = x1_of_t(t_test, K, x0)
        reconstruction_error = np.max(np.abs(x1_original - x1_reconstructed))

        print(f"\nReconstruction Verification:")
        print(f"  Max reconstruction error: {reconstruction_error:.2e}")
        print(
            f"  Reconstruction quality: {'Excellent' if reconstruction_error < 1e-10 else 'Good' if reconstruction_error < 1e-6 else 'Poor'}"
        )

        # Analyze hidden state structure
        print(f"\nHidden State Analysis:")
        print(f"  Initial state x0 norm: {np.linalg.norm(x0):.4f}")
        print(f"  Initial state range: [{x0.min():.4f}, {x0.max():.4f}]")
        print(f"  x1(0) = {x0[0]:.4f} (observable coordinate)")

        # Return results for further analysis
        return {
            "K": K,
            "x0": x0,
            "U": U,
            "eigenvals": K_eigenvals,
            "condition_number": K_cond,
            "reconstruction_error": reconstruction_error,
            "frobenius_norm": K_frobenius,
        }

    except Exception as e:
        print(f"Error constructing K matrix: {e}")
        return None


def plot_hidden_state_dynamics(t, ln_Q, K_analysis, experiment_name=""):
    """Plot the full hidden state dynamics and K matrix structure."""
    if K_analysis is None:
        print("No K matrix analysis available for plotting")
        return

    K = K_analysis["K"]
    x0 = K_analysis["x0"]
    m = K.shape[0]

    # Create comprehensive plot
    fig = plt.figure(figsize=(16, 12))

    # Simulate full hidden state evolution
    t_sim = np.linspace(0, max(t[-1], 2.0), 1000)
    # Solve dx/dt = -K x with initial condition x0
    eigenvals, eigenvecs = np.linalg.eigh(K)
    alpha = eigenvecs.T @ x0
    # Compute exponential matrix: alpha[i] * exp(-eigenvals[i] * t_sim) for each mode i
    exp_terms = alpha[:, np.newaxis] * np.exp(-eigenvals[:, np.newaxis] * t_sim)
    # Transform back to original coordinates: x(t) = eigenvecs @ exp_terms
    x_full = eigenvecs @ exp_terms

    # Plot 1: All hidden state components
    ax1 = plt.subplot(2, 4, 1)
    colors = plt.cm.tab10(np.linspace(0, 1, m))
    for i in range(m):
        ax1.plot(t_sim, x_full[i, :], "-", color=colors[i], alpha=0.7, label=f"x_{i+1}(t)")
    ax1.plot(t, ln_Q, "ko", markersize=3, alpha=0.8, label="ln(Q) data")
    ax1.set_xlabel("Time")
    ax1.set_ylabel("State Value")
    ax1.set_title(f"Hidden State Evolution - {experiment_name}")
    ax1.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
    ax1.grid(True, alpha=0.3)

    # Plot 2: Observable coordinate x1(t) vs data
    ax2 = plt.subplot(2, 4, 2)
    ax2.plot(t, ln_Q, "ko", markersize=4, alpha=0.8, label="ln(Q) data")
    ax2.plot(t_sim, x_full[0, :], "r-", linewidth=2, label="x₁(t) from K dynamics")
    ax2.set_xlabel("Time")
    ax2.set_ylabel("ln(Q)")
    ax2.set_title(f"Observable Coordinate - {experiment_name}")
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # Plot 3: K matrix heatmap
    ax3 = plt.subplot(2, 4, 3)
    im = ax3.imshow(K, cmap="RdBu_r", aspect="auto")
    ax3.set_title("K Matrix Structure")
    ax3.set_xlabel("Column Index")
    ax3.set_ylabel("Row Index")
    plt.colorbar(im, ax=ax3, shrink=0.8)

    # Plot 4: K matrix eigenvalues
    ax4 = plt.subplot(2, 4, 4)
    eigenvals_sorted = np.sort(K_analysis["eigenvals"])[::-1]
    ax4.semilogy(eigenvals_sorted, "bo-", markersize=4)
    ax4.set_xlabel("Eigenvalue Index")
    ax4.set_ylabel("Eigenvalue")
    ax4.set_title("K Matrix Eigenspectrum")
    ax4.grid(True, alpha=0.3)

    # Plot 5: Initial state x0
    ax5 = plt.subplot(2, 4, 5)
    ax5.bar(range(m), x0, color=colors, alpha=0.7)
    ax5.set_xlabel("State Index")
    ax5.set_ylabel("Initial Value")
    ax5.set_title("Initial Hidden State x₀")
    ax5.grid(True, alpha=0.3)

    # Plot 6: State evolution in phase space (first 3 components if m >= 3)
    if m >= 3:
        ax6 = plt.subplot(2, 4, 6, projection="3d")
        ax6.plot(x_full[0, :], x_full[1, :], x_full[2, :], "b-", alpha=0.7)
        ax6.scatter(x0[0], x0[1], x0[2], color="red", s=50, label="Initial")
        ax6.scatter(x_full[0, -1], x_full[1, -1], x_full[2, -1], color="green", s=50, label="Final")
        ax6.set_xlabel("x₁")
        ax6.set_ylabel("x₂")
        ax6.set_zlabel("x₃")
        ax6.set_title("3D Phase Portrait")
        ax6.legend()
    else:
        ax6 = plt.subplot(2, 4, 6)
        if m >= 2:
            ax6.plot(x_full[0, :], x_full[1, :], "b-", alpha=0.7)
            ax6.scatter(x0[0], x0[1], color="red", s=50, label="Initial")
            ax6.scatter(x_full[0, -1], x_full[1, -1], color="green", s=50, label="Final")
            ax6.set_xlabel("x₁")
            ax6.set_ylabel("x₂")
            ax6.set_title("2D Phase Portrait")
            ax6.legend()
        else:
            ax6.plot(t_sim, x_full[0, :], "b-")
            ax6.set_title("Single State")
        ax6.grid(True, alpha=0.3)

    # Plot 7: Relaxation rates comparison
    ax7 = plt.subplot(2, 4, 7)
    # Get the original fitted rates
    active_lambdas = np.diag(K_analysis.get("original_K", K))
    ax7.semilogx(eigenvals_sorted, "ro-", markersize=4, label="K matrix eigenvalues")
    if len(active_lambdas) > 0:
        ax7.semilogx(np.sort(active_lambdas)[::-1], "bs-", markersize=4, alpha=0.7, label="Original fitted rates")
    ax7.set_ylabel("Rate")
    ax7.set_xlabel("Mode Index")
    ax7.set_title("Rate Comparison")
    ax7.legend()
    ax7.grid(True, alpha=0.3)

    # Plot 8: Hidden state convergence
    ax8 = plt.subplot(2, 4, 8)
    # Compute state norms over time
    state_norms = np.linalg.norm(x_full, axis=0)
    ax8.semilogy(t_sim, state_norms, "g-", linewidth=2, label="||x(t)||")
    ax8.semilogy(t_sim, np.abs(x_full[0, :]), "r--", linewidth=1.5, label="|x₁(t)|")
    ax8.set_xlabel("Time")
    ax8.set_ylabel("Magnitude")
    ax8.set_title("State Magnitude Evolution")
    ax8.legend()
    ax8.grid(True, alpha=0.3)

    plt.tight_layout()

    # Save the plot
    filename = f"hidden_state_dynamics_{experiment_name.lower()}.png"
    filepath = OUT_DIR / filename
    plt.savefig(filepath, dpi=150, bbox_inches="tight")
    print(f"Saved hidden state plot to: {filepath}")

    # Try to show plot
    try:
        plt.show()
    except Exception as e:
        print(f"Display warning: {e}")


def reconstruct_concentrations_from_lnQ(t, ln_Q_fit, A_orig, B_orig, C_orig):
    """Reconstruct concentrations A(t), B(t), C(t) from fitted ln(Q) using conservation laws."""
    # Initial concentrations
    A0, B0, C0 = A_orig[0], B_orig[0], C_orig[0]

    # Conservation constants for A + B <-> 2C
    # A(t) + C(t)/2 = A0 + C0/2 = alpha (constant)
    # B(t) + C(t)/2 = B0 + C0/2 = beta (constant)
    alpha = A0 + C0 / 2
    beta = B0 + C0 / 2

    Q_fit = np.exp(ln_Q_fit)

    # For each time point, solve Q = C^2/((alpha - C/2)(beta - C/2)) for C
    C_fit = np.zeros_like(t)
    A_fit = np.zeros_like(t)
    B_fit = np.zeros_like(t)

    for i, Q_val in enumerate(Q_fit):
        # Rearrange Q = C^2/((alpha - C/2)(beta - C/2)) to quadratic equation
        # Q(alpha - C/2)(beta - C/2) = C^2
        # Q(alpha*beta - alpha*C/2 - beta*C/2 + C^2/4) = C^2
        # Q*alpha*beta - Q*(alpha+beta)*C/2 + Q*C^2/4 = C^2
        # (Q/4 - 1)*C^2 - Q*(alpha+beta)*C/2 + Q*alpha*beta = 0

        a = Q_val / 4 - 1
        b = -Q_val * (alpha + beta) / 2
        c = Q_val * alpha * beta

        # Solve quadratic equation ax^2 + bx + c = 0
        discriminant = b**2 - 4 * a * c

        if discriminant < 0:
            # Fallback to original value if no real solution
            C_fit[i] = C_orig[i]
        else:
            sqrt_disc = np.sqrt(discriminant)
            C1 = (-b + sqrt_disc) / (2 * a) if abs(a) > 1e-12 else -c / b
            C2 = (-b - sqrt_disc) / (2 * a) if abs(a) > 1e-12 else -c / b

            # Choose the physically meaningful solution (positive concentrations)
            A1 = alpha - C1 / 2
            B1 = beta - C1 / 2
            A2 = alpha - C2 / 2
            B2 = beta - C2 / 2

            # Pick solution with all positive concentrations and closest to original
            if C1 >= 0 and A1 >= 0 and B1 >= 0:
                if C2 >= 0 and A2 >= 0 and B2 >= 0:
                    # Both solutions valid, pick closer to original
                    err1 = abs(C1 - C_orig[i])
                    err2 = abs(C2 - C_orig[i])
                    if err1 <= err2:
                        C_fit[i] = C1
                    else:
                        C_fit[i] = C2
                else:
                    C_fit[i] = C1
            elif C2 >= 0 and A2 >= 0 and B2 >= 0:
                C_fit[i] = C2
            else:
                # No valid solution, use original
                C_fit[i] = C_orig[i]

        # Compute A and B from conservation laws
        A_fit[i] = alpha - C_fit[i] / 2
        B_fit[i] = beta - C_fit[i] / 2

    return A_fit, B_fit, C_fit


def plot_concentration_space_fits(t, A_orig, B_orig, C_orig, ln_Q_fit, experiment_name=""):
    """Plot original and fitted concentrations in concentration space."""
    print(f"Creating concentration space plot for {experiment_name}")

    # Reconstruct concentrations from fitted ln(Q)
    A_fit, B_fit, C_fit = reconstruct_concentrations_from_lnQ(t, ln_Q_fit, A_orig, B_orig, C_orig)

    # Create the plot
    fig, ax = plt.subplots(1, 1, figsize=(10, 6))

    # Plot original data (solid lines)
    ax.plot(t, A_orig, "-", linewidth=2, color="blue", label="A (data)", alpha=0.8)
    ax.plot(t, B_orig, "-", linewidth=2, color="red", label="B (data)", alpha=0.8)
    ax.plot(t, C_orig, "-", linewidth=2, color="green", label="C (data)", alpha=0.8)

    # Plot fitted reconstructions (dashed lines)
    ax.plot(t, A_fit, "--", linewidth=2, color="blue", label="A (fit)", alpha=0.7)
    ax.plot(t, B_fit, "--", linewidth=2, color="red", label="B (fit)", alpha=0.7)
    ax.plot(t, C_fit, "--", linewidth=2, color="green", label="C (fit)", alpha=0.7)

    ax.set_xlabel("Time")
    ax.set_ylabel("Concentration")
    ax.set_title(f"Concentration Space Comparison - {experiment_name}")
    ax.legend(loc="best")
    ax.grid(True, alpha=0.3)

    # Calculate and display RMS errors
    rmse_A = np.sqrt(np.mean((A_orig - A_fit) ** 2))
    rmse_B = np.sqrt(np.mean((B_orig - B_fit) ** 2))
    rmse_C = np.sqrt(np.mean((C_orig - C_fit) ** 2))

    # Add text box with errors
    textstr = f"RMSE:\nA: {rmse_A:.4f}\nB: {rmse_B:.4f}\nC: {rmse_C:.4f}"
    props = dict(boxstyle="round", facecolor="wheat", alpha=0.8)
    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10, verticalalignment="top", bbox=props)

    plt.tight_layout()

    # Save the plot
    filename = f"concentration_space_fit_{experiment_name.lower()}.png"
    filepath = OUT_DIR / filename
    plt.savefig(filepath, dpi=150, bbox_inches="tight")
    print(f"Saved concentration space plot to: {filepath}")

    # Try to show plot
    try:
        plt.show()
    except Exception as e:
        print(f"Display warning: {e}")

    return rmse_A, rmse_B, rmse_C


def main():
    """Main analysis function."""
    print("=" * 60)
    print("LOG-LINEAR FITTING OF CM TRAJECTORIES")
    print("=" * 60)

    # Load CM trajectory data
    try:
        forward_df, reverse_df, params = load_cm_trajectory_data()
    except FileNotFoundError as e:
        print(f"Error: {e}")
        return

    # Compute true equilibrium constant
    true_keq = compute_true_keq(params)
    if true_keq:
        print(f"True equilibrium constant: {true_keq:.4e}")

    # Process both experiments
    experiments = [("Forward", forward_df), ("Reverse", reverse_df)]

    best_fits = {}

    for exp_name, df in experiments:
        print(f"\n{'='*60}")
        print(f"ANALYZING {exp_name.upper()} EXPERIMENT")
        print(f"{'='*60}")

        # Extract data
        t = df["t"].values
        A = df["A"].values
        B = df["B"].values
        C = df["C"].values

        # Compute ln(Q)
        Q = compute_reaction_quotient(A, B, C)
        ln_Q = np.log(Q)

        print(f"Time range: [{t[0]:.3f}, {t[-1]:.3f}]")
        print(f"Number of data points: {len(t)}")

        # Analyze trajectory features
        analyze_trajectory_features(t, ln_Q, exp_name)

        # Fit with different parameters
        results = fit_trajectory_with_different_params(t, ln_Q, true_keq)

        # Plot results
        best_name, best_fit = plot_fitting_results(t, ln_Q, results, true_keq, exp_name)
        best_fits[exp_name] = (best_name, best_fit)

        # Plot hidden state dynamics for the best fit
        best_K_analysis = results[best_name]["K_analysis"]
        plot_hidden_state_dynamics(t, ln_Q, best_K_analysis, exp_name)

        # Plot concentration space comparison
        rmse_A, rmse_B, rmse_C = plot_concentration_space_fits(t, A, B, C, best_fit.y_hat, exp_name)

        # Store K analysis with best fits for later use
        best_fits[exp_name] = (best_name, best_fit, best_K_analysis, rmse_A, rmse_B, rmse_C)

        # Summary for this experiment
        successful_results = {k: v for k, v in results.items() if v["success"]}
        print(f"\n--- {exp_name} Experiment Summary ---")
        print(f"Successful fits: {len(successful_results)}/{len(results)}")
        if successful_results:
            best_r2 = max(r["fit"].r2 for r in successful_results.values())
            print(f"Best R²: {best_r2:.4f} ({best_name})")
            print(f"Best fit active modes: {best_fit.active_idx.size}/{best_fit.lambdas.size}")

    # Final comparison
    print(f"\n{'='*60}")
    print("OVERALL SUMMARY")
    print(f"{'='*60}")

    for exp_name, fit_data in best_fits.items():
        best_name, best_fit, K_analysis, rmse_A, rmse_B, rmse_C = fit_data
        sparsity = (1 - best_fit.active_idx.size / best_fit.lambdas.size) * 100
        print(f"{exp_name} - Best: {best_name}, R² = {best_fit.r2:.4f}, K_eq = {best_fit.K_eq():.4e}")
        print(f"  Active modes: {best_fit.active_idx.size}/{best_fit.lambdas.size} (sparsity: {sparsity:.1f}%)")
        if true_keq:
            keq_error = abs(best_fit.K_eq() - true_keq) / true_keq * 100
            print(f"  K_eq error: {keq_error:.1f}%")

        # Add K matrix summary
        if K_analysis:
            print(
                f"  K matrix: {K_analysis['K'].shape[0]}×{K_analysis['K'].shape[1]}, cond = {K_analysis['condition_number']:.1e}"
            )
            print(f"  Reconstruction error: {K_analysis['reconstruction_error']:.1e}")

        # Add concentration space reconstruction errors
        print(f"  Concentration RMSE: A={rmse_A:.4f}, B={rmse_B:.4f}, C={rmse_C:.4f}")

    print("\nSparsity Analysis:")
    avg_sparsity = np.mean(
        [(1 - best_fit.active_idx.size / best_fit.lambdas.size) * 100 for _, best_fit, _, _, _, _ in best_fits.values()]
    )
    avg_active = np.mean([best_fit.active_idx.size for _, best_fit, _, _, _, _ in best_fits.values()])
    print(f"Average sparsity: {avg_sparsity:.1f}% (using {avg_active:.1f} modes on average)")
    print("CVXPY L1 regularization successfully promotes sparse solutions while")
    print("maintaining excellent fit quality.")

    print("\nK Matrix Analysis Summary:")
    K_analyses = [K_analysis for _, _, K_analysis, _, _, _ in best_fits.values() if K_analysis]
    if K_analyses:
        avg_cond = np.mean([K_analysis["condition_number"] for K_analysis in K_analyses])
        avg_recon_error = np.mean([K_analysis["reconstruction_error"] for K_analysis in K_analyses])
        avg_K_size = np.mean([K_analysis["K"].shape[0] for K_analysis in K_analyses])
        print(f"Average K matrix size: {avg_K_size:.1f}×{avg_K_size:.1f}")
        print(f"Average condition number: {avg_cond:.1e}")
        print(f"Average reconstruction error: {avg_recon_error:.1e}")
        print("K matrix construction from exponential modes provides excellent")
        print("reconstruction of the observable ln(Q) dynamics from hidden state evolution.")

    print("\nConcentration Space Analysis Summary:")
    avg_rmse_A = np.mean([rmse_A for _, _, _, rmse_A, _, _ in best_fits.values()])
    avg_rmse_B = np.mean([rmse_B for _, _, _, _, rmse_B, _ in best_fits.values()])
    avg_rmse_C = np.mean([rmse_C for _, _, _, _, _, rmse_C in best_fits.values()])
    total_rmse = np.sqrt((avg_rmse_A**2 + avg_rmse_B**2 + avg_rmse_C**2) / 3)
    print(f"Average concentration RMSE: A={avg_rmse_A:.4f}, B={avg_rmse_B:.4f}, C={avg_rmse_C:.4f}")
    print(f"Overall concentration RMSE: {total_rmse:.4f}")
    print("The log-linear fits successfully reconstruct concentration dynamics")
    print("through conservation law inversion from the fitted ln(Q) trajectories.")

    print("\nConclusion:")
    avg_r2 = np.mean([best_fit.r2 for _, best_fit, _, _, _, _ in best_fits.values()])
    if avg_r2 > 0.99:
        print(f"Excellent fit quality (avg R² = {avg_r2:.4f})")
    elif avg_r2 > 0.95:
        print(f"Good fit quality (avg R² = {avg_r2:.4f})")
    elif avg_r2 > 0.9:
        print(f"Reasonable fit quality (avg R² = {avg_r2:.4f})")
    else:
        print(f"Poor fit quality (avg R² = {avg_r2:.4f}) - CM dynamics may be too complex")

    print("The CVXPY-based log-linear exponential mixture fitting with MOSEK solver")
    print("demonstrates that CM dynamics can be approximated with high fidelity using")
    print("sparse combinations of exponential relaxation modes. L1 regularization")
    print("promotes interpretable models by automatically selecting the most")
    print("relevant time scales governing the reaction quotient evolution.")
    print("\nThe K matrix analysis reveals the underlying linear dynamics structure:")
    print("dx/dt = -K x, where x₁(t) = ln(Q) is the observable coordinate and")
    print("x₂(t), x₃(t), ... are hidden states that collectively generate the")
    print("complex CM relaxation behavior through linear superposition.")


if __name__ == "__main__":
    main()
